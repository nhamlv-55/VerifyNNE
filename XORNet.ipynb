{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4225\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "class XORNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(2,2)\n",
    "        self.linear2 = torch.nn.Linear(2,2)\n",
    "    def forward(self, x):\n",
    "        output = self.linear1(x)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        output = self.linear2(output)\n",
    "        return output\n",
    "\n",
    "def gen_XOR_dataset(n:int = 100):\n",
    "    \"\"\"\n",
    "        we agree that signal that is less than 0.3 is False, greater than 0.7 is True\n",
    "    \"\"\"\n",
    "    inputs = np.random.uniform(0, 1, n)\n",
    "\n",
    "    dataset = []\n",
    "    for i in inputs:\n",
    "        for j in inputs:\n",
    "            if i <= 0.3 and j<=0.3: #00\n",
    "                dataset.append([[i,j], 0])\n",
    "            elif i<=0.3 and j>=0.7: #01\n",
    "                dataset.append([[i,j], 1])\n",
    "            elif i>=0.7 and j<=0.3: #10\n",
    "                dataset.append([[i,j], 1])\n",
    "            elif i>=0.7 and j>=0.7: #11\n",
    "                dataset.append([[i,j], 0])\n",
    "\n",
    "    random.shuffle(dataset)    \n",
    "    return dataset\n",
    "\n",
    "dataset = gen_XOR_dataset()\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2957, 2])\n",
      "torch.Size([2957])\n"
     ]
    }
   ],
   "source": [
    "xornet  = XORNet()\n",
    "crit  = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(xornet.parameters())\n",
    "\n",
    "n_train = int(len(dataset)*0.7)\n",
    "trainset = dataset[:n_train]\n",
    "testset = dataset[n_train:]\n",
    "traintensor = torch.stack([torch.Tensor(input) for input, label in trainset])\n",
    "trainlabels = torch.LongTensor([output for input, output in trainset])\n",
    "print(traintensor.shape)\n",
    "print(trainlabels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8650, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 0.3533, -0.8217], grad_fn=<SelectBackward>)\n",
      "tensor(0.6072, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 0.7136, -0.9146], grad_fn=<SelectBackward>)\n",
      "tensor(0.2291, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 1.7780, -1.9224], grad_fn=<SelectBackward>)\n",
      "tensor(0.0787, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 2.7800, -2.9040], grad_fn=<SelectBackward>)\n",
      "tensor(0.0369, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 3.7165, -3.8265], grad_fn=<SelectBackward>)\n",
      "tensor(0.0200, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 4.6101, -4.7089], grad_fn=<SelectBackward>)\n",
      "tensor(0.0116, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 5.5078, -5.5969], grad_fn=<SelectBackward>)\n",
      "tensor(0.0070, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 6.4483, -6.5282], grad_fn=<SelectBackward>)\n",
      "tensor(0.0043, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 7.4307, -7.5019], grad_fn=<SelectBackward>)\n",
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "sample tensor([0.0312, 0.1243])\n",
      "sample pred tensor([ 8.4631, -8.5258], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "EPOCH = 10000\n",
    "for e in range(EPOCH):\n",
    "    optimizer.zero_grad()\n",
    "    pred = xornet(traintensor)\n",
    "    loss = crit(pred, trainlabels)\n",
    "    if e%1000 == 0:\n",
    "        print(loss)\n",
    "        print(\"sample\", traintensor[0])\n",
    "        print(\"sample pred\", pred[0])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       683\n",
      "           1       1.00      1.00      1.00       585\n",
      "\n",
      "    accuracy                           1.00      1268\n",
      "   macro avg       1.00      1.00      1.00      1268\n",
      "weighted avg       1.00      1.00      1.00      1268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(testset, xornet):\n",
    "    testtensor = torch.stack([torch.Tensor(input) for input, label in testset])\n",
    "    testlabels = torch.LongTensor([output for input, output in testset])\n",
    "    pred = xornet(testtensor)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    print(classification_report(testlabels, pred))\n",
    "\n",
    "evaluate(testset, xornet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('abc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eaeb03013edc1e01ded2b62fc4f923950657015aa068eeb3171b619219008c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
