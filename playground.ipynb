{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19791.091, 0.0, 0.0, 650.0, 600.0, 7.5188840201005975]\n",
      "min [0.0, -3.141593, -3.141593, 100.0, 0.0]\n",
      "max [60760.0, 3.141593, 3.141593, 1200.0, 1200.0]\n",
      "torch.Size([10000, 5]) torch.Size([10000])\n",
      "<torch.utils.data.dataset.TensorDataset object at 0x7fe67f3e5bd0>\n",
      "<ReluPatterns.Patterns object at 0x7fe67f6e7210>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "           1       1.00      1.00      1.00      2000\n",
      "           2       1.00      1.00      1.00      2000\n",
      "           3       1.00      1.00      1.00      2000\n",
      "           4       1.00      1.00      1.00      2000\n",
      "\n",
      "    accuracy                           1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "from AcasXuNet import AcasXu\n",
    "from ReluPatterns import Patterns\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "PATH = '/home/nle/workspace/VerifyNNE/datasets/ACAS/acas_nets/ACASXU_run2a_1_3_batch_2000.nnet'\n",
    "network = AcasXu(PATH)\n",
    "print(network.means)\n",
    "print(\"min\", network.mins)\n",
    "print(\"max\", network.maxs)\n",
    "dataset: Tuple[Tensor] = torch.load('/home/nle/workspace/VerifyNNE/datasets/ACAS/acas_nets/AcasNetID<1,3>-normed-train.pt')\n",
    "\n",
    "dataset_train = TensorDataset(dataset[0], dataset[1])\n",
    "print(dataset[0].shape, dataset[1].shape)\n",
    "print(dataset_train)\n",
    "\n",
    "loader = DataLoader(dataset_train, batch_size=dataset[0].shape[0], shuffle=True)\n",
    "\n",
    "all_patterns: Patterns = Patterns(model = network,\n",
    "                        dataloader = loader,\n",
    "                        labels = range(5),\n",
    "                        layers = ['layer0', 'layer1', 'layer2', 'layer3', 'layer4'])\n",
    "\n",
    "print(all_patterns)\n",
    "all_preds: List[int] = []\n",
    "true_labels: List[int] = []\n",
    "network.register_log()\n",
    "for inputs, outputs in loader:\n",
    "    raw_pred = network(inputs)\n",
    "    pred: List[int] = torch.argmin(raw_pred, dim = 1).squeeze().tolist()\n",
    "    all_preds.extend(pred)\n",
    "    true_labels.extend(outputs.squeeze().tolist())\n",
    "\n",
    "print(classification_report(true_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 250)\n",
      "[  2  20  27  30  43  59  61  63  65  69  73  87  99 104 132 141 145 152\n",
      " 153 164 165 175 176 178 182 185 186 188 201 205 207 208 211 220 221 223\n",
      " 226   1  29  96 106 148 166 174 179 192 232 243]\n",
      "(2000, 250)\n",
      "[  2  27  30  59  63  65  69  73  87  99 104 132 160 165 170 175 186 188\n",
      " 207 208 211 220 223 237 238 245  29 106 148 179 232 243]\n",
      "(2000, 250)\n",
      "[  2  27  30  63  65  69  73  87  99 104 132 165 176 186 188 205 207 208\n",
      " 211  29 148 179 232 243]\n",
      "(2000, 250)\n",
      "[  2  27  30  63  65  69  73  87  99 104 132 165 188 207 208 220 245  29\n",
      " 148 179 232]\n",
      "(2000, 250)\n",
      "[  2  27  30  63  65  69  73  87  99 104 132 165 188 207 208  29 148 179\n",
      " 232]\n"
     ]
    }
   ],
   "source": [
    "EPSILON = 0\n",
    "alpha_patterns = {}\n",
    "for label in all_patterns.label2patterns:\n",
    "    patterns = all_patterns.label2patterns[label]\n",
    "    print(patterns.shape)\n",
    "\n",
    "\n",
    "    relu_sum = np.sum(patterns, axis = 0).squeeze()\n",
    "\n",
    "    stable_idx = np.concatenate([np.where(relu_sum<=EPSILON*patterns.shape[0]), \n",
    "                                    np.where(relu_sum>=(1-EPSILON)*patterns.shape[0])],\n",
    "                                axis = 1\n",
    "                                ).squeeze()\n",
    "    print(stable_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('abc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eaeb03013edc1e01ded2b62fc4f923950657015aa068eeb3171b619219008c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
