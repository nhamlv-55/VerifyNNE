{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:22<00:00, 2270.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 (3539, 2568)\n",
      "9 (3891, 2568)\n",
      "1 (4079, 2568)\n",
      "2 (2372, 2568)\n",
      "7 (3518, 2568)\n",
      "8 (3999, 2568)\n",
      "4 (3075, 2568)\n",
      "3 (2477, 2568)\n",
      "0 (3344, 2568)\n",
      "5 (3291, 2568)\n"
     ]
    }
   ],
   "source": [
    "#cifar 10 dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\"\"\"\n",
    "File format:\n",
    "<pred label> <true label>\n",
    "101001000011111....\n",
    "\"\"\"\n",
    "\n",
    "N: int = 50000\n",
    "PATH:str = 'trainset_cifar10_small.onnx'\n",
    "ONLY_CORRECT_PRED = True #whether we should extract pattern from wrong predictions or not\n",
    "\n",
    "\n",
    "all_patterns = {}\n",
    "\n",
    "for idx in tqdm(range(N)):\n",
    "    with open(os.path.join(PATH, \"reluBitmap_{}.txt\").format(idx)) as f:\n",
    "        raw = f.readlines()\n",
    "        pred_label, true_label = raw[0].strip().split()\n",
    "        if ONLY_CORRECT_PRED:\n",
    "            if pred_label != true_label: continue\n",
    "        bitmap = [*raw[1].strip()] #convert the string \"01000...\" to the list [\"0\", \"1\", \"0\", \"0\", ...]\n",
    "        bitmap = [int(b) for b in bitmap] #convert the list of string to the list of int\n",
    "        if pred_label in all_patterns:\n",
    "            all_patterns[pred_label].append(bitmap)\n",
    "        else:\n",
    "            all_patterns[pred_label] = []\n",
    "            all_patterns[pred_label].append(bitmap)\n",
    "\n",
    "for k in all_patterns.keys():\n",
    "    all_patterns[k] = np.array(all_patterns[k])\n",
    "\n",
    "    print(k, all_patterns[k].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "n_sample 3539\n",
      "[2379 2383 2384 2386 2394 2397 2401 2406 2409 2410 2411 2422 2426 2439\n",
      " 2441 2446 2448 2452 2455 2456 2457 2462 2467 2469 2474 2478 2485 2486\n",
      " 2489 2493 2498 2500 2501 2520   66   67   68   69   81   82   83   84\n",
      "   85   97   98   99  100  112  113  114  129 2514 2524 2525 2526 2528\n",
      " 2529 2535 2540 2541 2548 2551 2553 2559 2562 2564]\n",
      "9\n",
      "n_sample 3891\n",
      "[2382 2383 2385 2388 2393 2394 2395 2399 2402 2407 2412 2415 2416 2419\n",
      " 2420 2423 2424 2425 2427 2428 2429 2430 2435 2436 2440 2441 2445 2448\n",
      " 2454 2456 2458 2461 2463 2473 2477 2479 2480 2482 2483 2487 2490 2494\n",
      " 2495 2497 2530 2534 2537 2538 2550 2552 2504 2505 2507 2510 2514 2518\n",
      " 2519 2520 2532 2539 2546 2547 2549 2554 2557]\n",
      "1\n",
      "n_sample 4079\n",
      "[2376 2382 2383 2389 2393 2394 2398 2399 2404 2406 2407 2410 2415 2418\n",
      " 2419 2420 2424 2427 2428 2429 2430 2435 2436 2438 2443 2445 2448 2449\n",
      " 2456 2458 2461 2463 2477 2479 2480 2483 2487 2491 2494 2495 2497 2522\n",
      " 2526 2530 2534 2537 2538 2550 2552 2560 2505 2507 2510 2532 2539 2544\n",
      " 2546 2547 2549 2557 2563 2564]\n",
      "2\n",
      "n_sample 2372\n",
      "[2379 2383 2384 2397 2401 2407 2409 2416 2417 2423 2433 2437 2443 2445\n",
      " 2446 2447 2450 2451 2452 2455 2456 2457 2461 2465 2471 2474 2475 2483\n",
      " 2485 2486 2493 2495 2496 2497 2500 2507 2512 2515 2524 2528 2529 2543\n",
      " 2553 2556 2562 2565]\n",
      "7\n",
      "n_sample 3518\n",
      "[2377 2379 2380 2382 2383 2384 2386 2388 2396 2398 2401 2409 2410 2411\n",
      " 2413 2417 2423 2425 2427 2431 2437 2439 2440 2441 2446 2450 2452 2453\n",
      " 2455 2457 2458 2461 2467 2469 2470 2473 2485 2486 2489 2494 2495 2496\n",
      " 2497 2508 2537 2544 2513 2514 2518 2519 2524 2529 2540 2547 2549 2553\n",
      " 2558 2563 2565]\n",
      "8\n",
      "n_sample 3999\n",
      "[ 675  676  677  678  679  680  681  682  683  684  685  686  687  688\n",
      "  689  690  691  692  693  694  695  696  697  698  699  700  701  702\n",
      "  703  704  705  706  707  708  709  710  711  712  713  714  715  716\n",
      "  717  718  719  720  721  722  723  724  732  733  734  735  736  749\n",
      "  750 1944 1945 1946 1947 1948 1949 1950 1951 1954 1955 2053 2054 2379\n",
      " 2385 2389 2392 2393 2395 2399 2403 2406 2407 2408 2414 2415 2416 2417\n",
      " 2419 2420 2425 2428 2429 2430 2432 2433 2435 2442 2443 2445 2447 2448\n",
      " 2456 2461 2463 2472 2473 2474 2475 2477 2479 2480 2481 2483 2484 2490\n",
      " 2494 2495 2497 2498 2524 2526 2534 2558 2559 2567 1125 1126 1127 1128\n",
      " 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142\n",
      " 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156\n",
      " 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170\n",
      " 1171 1172 1184 2505 2507 2508 2510 2511 2513 2522 2523 2531 2532 2533\n",
      " 2535 2539 2543 2560 2564 2566]\n",
      "4\n",
      "n_sample 3075\n",
      "[2379 2382 2383 2384 2396 2401 2409 2411 2413 2437 2439 2446 2449 2450\n",
      " 2452 2455 2457 2461 2465 2469 2471 2485 2486 2489 2493 2495 2496 2500\n",
      " 2503 2512 2514 2515 2522 2524 2525 2529 2535 2536 2540 2553 2564 2565]\n",
      "3\n",
      "n_sample 2477\n",
      "[2379 2382 2383 2384 2386 2388 2394 2396 2401 2409 2410 2411 2432 2437\n",
      " 2439 2441 2443 2445 2446 2448 2450 2452 2455 2456 2457 2461 2471 2474\n",
      " 2478 2482 2485 2486 2489 2496 2497 2500 2501 2544 2507 2512 2514 2515\n",
      " 2523 2524 2527 2528 2529 2540 2541 2548 2549 2553 2558 2562 2565]\n",
      "0\n",
      "n_sample 3344\n",
      "[ 675  676  677  678  679  680  681  682  683  684  685  686  687  688\n",
      "  689  690  691  692  693  694  695  696  697  698  699  700  701  702\n",
      "  703  704  705  711  712  713  714  715  716  717  718  719  734 1980\n",
      " 2055 2377 2379 2385 2389 2390 2392 2393 2399 2404 2405 2407 2414 2415\n",
      " 2416 2417 2419 2423 2424 2427 2429 2433 2437 2442 2444 2445 2447 2449\n",
      " 2456 2461 2463 2465 2475 2477 2479 2480 2481 2483 2484 2494 2495 2497\n",
      " 2503 2534 1129 1130 1131 1133 1134 1135 2505 2507 2512 2513 2522 2529\n",
      " 2531 2532 2533 2535 2539 2543 2555]\n",
      "5\n",
      "n_sample 3291\n",
      "[2103 2109 2379 2380 2382 2383 2384 2386 2388 2395 2396 2397 2398 2401\n",
      " 2405 2407 2409 2410 2411 2416 2417 2422 2425 2432 2437 2439 2440 2441\n",
      " 2443 2445 2446 2448 2450 2451 2452 2453 2455 2456 2457 2461 2467 2469\n",
      " 2470 2471 2473 2474 2475 2476 2482 2485 2486 2489 2490 2492 2495 2496\n",
      " 2497 2500 2501 2508 2516 2539 2544 2557 2507 2512 2514 2515 2524 2527\n",
      " 2528 2529 2540 2542 2548 2549 2553 2556 2558 2562 2565]\n",
      "{'6': {'stable_idx': [66, 67, 68, 69, 81, 82, 83, 84, 85, 97, 98, 99, 100, 112, 113, 114, 129, 2379, 2383, 2384, 2386, 2394, 2397, 2401, 2406, 2409, 2410, 2411, 2422, 2426, 2439, 2441, 2446, 2448, 2452, 2455, 2456, 2457, 2462, 2467, 2469, 2474, 2478, 2485, 2486, 2489, 2493, 2498, 2500, 2501, 2514, 2520, 2524, 2525, 2526, 2528, 2529, 2535, 2540, 2541, 2548, 2551, 2553, 2559, 2562, 2564], 'val': [3369, 3390, 3378, 3379, 3363, 3385, 3398, 3407, 3370, 3379, 3405, 3405, 3367, 3381, 3393, 3392, 3364, 161, 19, 152, 43, 40, 145, 46, 103, 127, 104, 47, 31, 86, 15, 83, 29, 107, 38, 78, 69, 65, 145, 92, 48, 150, 97, 55, 24, 28, 161, 156, 108, 105, 3388, 130, 3530, 3493, 3485, 3533, 3534, 3526, 3519, 3538, 3517, 3539, 3488, 3531, 3539, 3482]}, '9': {'stable_idx': [2382, 2383, 2385, 2388, 2393, 2394, 2395, 2399, 2402, 2407, 2412, 2415, 2416, 2419, 2420, 2423, 2424, 2425, 2427, 2428, 2429, 2430, 2435, 2436, 2440, 2441, 2445, 2448, 2454, 2456, 2458, 2461, 2463, 2473, 2477, 2479, 2480, 2482, 2483, 2487, 2490, 2494, 2495, 2497, 2504, 2505, 2507, 2510, 2514, 2518, 2519, 2520, 2530, 2532, 2534, 2537, 2538, 2539, 2546, 2547, 2549, 2550, 2552, 2554, 2557], 'val': [96, 77, 85, 82, 164, 76, 123, 59, 126, 150, 191, 74, 130, 77, 17, 64, 97, 151, 99, 60, 132, 91, 136, 106, 139, 44, 65, 176, 131, 12, 112, 22, 104, 97, 102, 81, 85, 90, 22, 51, 116, 132, 36, 9, 3799, 3886, 3798, 3876, 3769, 3868, 3823, 3837, 100, 3872, 148, 104, 107, 3866, 3714, 3851, 3790, 71, 135, 3721, 3706]}, '1': {'stable_idx': [2376, 2382, 2383, 2389, 2393, 2394, 2398, 2399, 2404, 2406, 2407, 2410, 2415, 2418, 2419, 2420, 2424, 2427, 2428, 2429, 2430, 2435, 2436, 2438, 2443, 2445, 2448, 2449, 2456, 2458, 2461, 2463, 2477, 2479, 2480, 2483, 2487, 2491, 2494, 2495, 2497, 2505, 2507, 2510, 2522, 2526, 2530, 2532, 2534, 2537, 2538, 2539, 2544, 2546, 2547, 2549, 2550, 2552, 2557, 2560, 2563, 2564], 'val': [137, 192, 117, 130, 31, 49, 104, 33, 47, 140, 11, 175, 4, 174, 57, 42, 68, 37, 24, 167, 84, 65, 59, 132, 139, 31, 128, 191, 13, 91, 28, 62, 46, 35, 14, 62, 39, 84, 174, 10, 22, 4076, 3973, 4059, 142, 151, 63, 4047, 140, 130, 101, 4060, 3933, 3968, 3908, 4026, 103, 82, 4058, 166, 4059, 4035]}, '2': {'stable_idx': [2379, 2383, 2384, 2397, 2401, 2407, 2409, 2416, 2417, 2423, 2433, 2437, 2443, 2445, 2446, 2447, 2450, 2451, 2452, 2455, 2456, 2457, 2461, 2465, 2471, 2474, 2475, 2483, 2485, 2486, 2493, 2495, 2496, 2497, 2500, 2507, 2512, 2515, 2524, 2528, 2529, 2543, 2553, 2556, 2562, 2565], 'val': [16, 54, 28, 60, 85, 21, 4, 59, 46, 51, 76, 40, 61, 14, 47, 93, 30, 116, 41, 86, 45, 54, 2, 16, 66, 41, 75, 62, 26, 34, 49, 24, 9, 2, 56, 2362, 2346, 2367, 2319, 2321, 2367, 2319, 2254, 2318, 2273, 2367]}, '7': {'stable_idx': [2377, 2379, 2380, 2382, 2383, 2384, 2386, 2388, 2396, 2398, 2401, 2409, 2410, 2411, 2413, 2417, 2423, 2425, 2427, 2431, 2437, 2439, 2440, 2441, 2446, 2450, 2452, 2453, 2455, 2457, 2458, 2461, 2467, 2469, 2470, 2473, 2485, 2486, 2489, 2494, 2495, 2496, 2497, 2508, 2513, 2514, 2518, 2519, 2524, 2529, 2537, 2540, 2544, 2547, 2549, 2553, 2558, 2563, 2565], 'val': [149, 95, 136, 16, 7, 8, 126, 121, 131, 67, 25, 91, 60, 11, 78, 86, 77, 138, 141, 144, 113, 89, 83, 113, 40, 93, 17, 148, 155, 84, 89, 15, 111, 86, 63, 134, 3, 43, 12, 158, 13, 52, 37, 81, 3429, 3502, 3418, 3508, 3512, 3513, 55, 3501, 158, 3413, 3484, 3498, 3517, 3442, 3501]}, '8': {'stable_idx': [675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 732, 733, 734, 735, 736, 749, 750, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1184, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1954, 1955, 2053, 2054, 2379, 2385, 2389, 2392, 2393, 2395, 2399, 2403, 2406, 2407, 2408, 2414, 2415, 2416, 2417, 2419, 2420, 2425, 2428, 2429, 2430, 2432, 2433, 2435, 2442, 2443, 2445, 2447, 2448, 2456, 2461, 2463, 2472, 2473, 2474, 2475, 2477, 2479, 2480, 2481, 2483, 2484, 2490, 2494, 2495, 2497, 2498, 2505, 2507, 2508, 2510, 2511, 2513, 2522, 2523, 2524, 2526, 2531, 2532, 2533, 2534, 2535, 2539, 2543, 2558, 2559, 2560, 2564, 2566, 2567], 'val': [113, 102, 101, 94, 105, 102, 101, 99, 84, 87, 97, 105, 102, 99, 106, 116, 118, 115, 111, 109, 117, 130, 124, 124, 123, 108, 103, 109, 110, 110, 122, 129, 121, 129, 130, 148, 154, 161, 153, 154, 156, 147, 145, 142, 126, 144, 154, 173, 175, 185, 191, 163, 149, 180, 192, 173, 198, 3853, 3862, 3864, 3874, 3874, 3867, 3876, 3871, 3869, 3870, 3876, 3871, 3882, 3873, 3876, 3853, 3844, 3856, 3853, 3851, 3851, 3855, 3854, 3849, 3866, 3851, 3854, 3866, 3854, 3866, 3837, 3833, 3831, 3838, 3829, 3830, 3814, 3823, 3829, 3833, 3820, 3827, 3830, 3845, 3847, 3825, 3813, 3805, 3807, 138, 131, 136, 138, 122, 124, 178, 186, 190, 173, 190, 186, 182, 66, 56, 162, 36, 135, 59, 181, 198, 8, 145, 114, 152, 75, 68, 62, 52, 168, 61, 120, 134, 81, 40, 162, 56, 68, 9, 81, 80, 2, 8, 27, 105, 129, 121, 37, 71, 18, 58, 177, 33, 190, 148, 125, 4, 1, 167, 3945, 3999, 3865, 3982, 3853, 3966, 3859, 3987, 172, 160, 3984, 3979, 3971, 10, 3926, 3973, 3895, 121, 94, 3865, 3819, 3996, 178]}, '4': {'stable_idx': [2379, 2382, 2383, 2384, 2396, 2401, 2409, 2411, 2413, 2437, 2439, 2446, 2449, 2450, 2452, 2455, 2457, 2461, 2465, 2469, 2471, 2485, 2486, 2489, 2493, 2495, 2496, 2500, 2503, 2512, 2514, 2515, 2522, 2524, 2525, 2529, 2535, 2536, 2540, 2553, 2564, 2565], 'val': [29, 109, 45, 52, 85, 70, 26, 44, 101, 29, 84, 40, 139, 55, 26, 103, 85, 63, 118, 102, 40, 45, 31, 84, 45, 55, 27, 132, 123, 3056, 2932, 3056, 2932, 3069, 3072, 3075, 3068, 3013, 3018, 3058, 2983, 3066]}, '3': {'stable_idx': [2379, 2382, 2383, 2384, 2386, 2388, 2394, 2396, 2401, 2409, 2410, 2411, 2432, 2437, 2439, 2441, 2443, 2445, 2446, 2448, 2450, 2452, 2455, 2456, 2457, 2461, 2471, 2474, 2478, 2482, 2485, 2486, 2489, 2496, 2497, 2500, 2501, 2507, 2512, 2514, 2515, 2523, 2524, 2527, 2528, 2529, 2540, 2541, 2544, 2548, 2549, 2553, 2558, 2562, 2565], 'val': [52, 104, 50, 24, 71, 107, 70, 86, 39, 63, 122, 58, 69, 101, 34, 28, 65, 113, 58, 61, 93, 32, 72, 28, 35, 58, 102, 45, 115, 114, 29, 39, 71, 104, 29, 35, 118, 2425, 2434, 2442, 2355, 2378, 2417, 2418, 2477, 2468, 2422, 2449, 105, 2447, 2422, 2475, 2444, 2477, 2474]}, '0': {'stable_idx': [675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 711, 712, 713, 714, 715, 716, 717, 718, 719, 734, 1129, 1130, 1131, 1133, 1134, 1135, 1980, 2055, 2377, 2379, 2385, 2389, 2390, 2392, 2393, 2399, 2404, 2405, 2407, 2414, 2415, 2416, 2417, 2419, 2423, 2424, 2427, 2429, 2433, 2437, 2442, 2444, 2445, 2447, 2449, 2456, 2461, 2463, 2465, 2475, 2477, 2479, 2480, 2481, 2483, 2484, 2494, 2495, 2497, 2503, 2505, 2507, 2512, 2513, 2522, 2529, 2531, 2532, 2533, 2534, 2535, 2539, 2543, 2555], 'val': [138, 139, 134, 117, 119, 119, 114, 116, 114, 120, 112, 110, 126, 145, 134, 138, 157, 148, 132, 131, 141, 134, 125, 134, 135, 138, 125, 141, 144, 134, 162, 155, 152, 155, 164, 159, 157, 158, 159, 149, 159, 3179, 3180, 3177, 3181, 3187, 3180, 150, 145, 149, 53, 85, 38, 127, 106, 106, 18, 137, 66, 20, 164, 23, 152, 74, 85, 37, 33, 21, 61, 48, 89, 157, 103, 11, 12, 102, 37, 0, 45, 37, 33, 13, 116, 153, 96, 10, 73, 157, 3, 0, 156, 3329, 3333, 3255, 3304, 3191, 3208, 3273, 3278, 3338, 30, 3282, 3277, 3294, 3332]}, '5': {'stable_idx': [2103, 2109, 2379, 2380, 2382, 2383, 2384, 2386, 2388, 2395, 2396, 2397, 2398, 2401, 2405, 2407, 2409, 2410, 2411, 2416, 2417, 2422, 2425, 2432, 2437, 2439, 2440, 2441, 2443, 2445, 2446, 2448, 2450, 2451, 2452, 2453, 2455, 2456, 2457, 2461, 2467, 2469, 2470, 2471, 2473, 2474, 2475, 2476, 2482, 2485, 2486, 2489, 2490, 2492, 2495, 2496, 2497, 2500, 2501, 2507, 2508, 2512, 2514, 2515, 2516, 2524, 2527, 2528, 2529, 2539, 2540, 2542, 2544, 2548, 2549, 2553, 2556, 2557, 2558, 2562, 2565], 'val': [134, 160, 26, 140, 108, 15, 11, 28, 50, 158, 32, 136, 156, 26, 125, 163, 7, 72, 3, 79, 47, 71, 130, 119, 60, 40, 149, 37, 24, 116, 17, 102, 39, 76, 14, 55, 18, 84, 11, 19, 118, 87, 114, 61, 69, 31, 54, 85, 129, 10, 9, 14, 119, 133, 25, 22, 26, 57, 63, 3194, 61, 3217, 3289, 3272, 54, 3246, 3263, 3291, 3271, 36, 3261, 3241, 74, 3167, 3135, 3290, 3267, 35, 3256, 3291, 3291]}}\n"
     ]
    }
   ],
   "source": [
    "DELTA = 0.05\n",
    "stable_relu_patterns = {}\n",
    "for k in all_patterns.keys():\n",
    "    print(k)\n",
    "    sum = all_patterns[k].sum(axis = 0)\n",
    "    n_sample = all_patterns[k].shape[0]\n",
    "    print(\"n_sample\", n_sample)\n",
    "    neg_relus = np.where(sum <= n_sample*DELTA)\n",
    "    pos_relus = np.where(sum >= n_sample*(1-DELTA))\n",
    "    stable_idx = np.concatenate([neg_relus, pos_relus], axis= 1).squeeze()\n",
    "    print(stable_idx)\n",
    "    stable_idx = np.sort(stable_idx)\n",
    "    \n",
    "    stable_relu_patterns[k] = {\"stable_idx\": stable_idx.tolist(), \n",
    "                               \"val\": [int(sum[idx]) for idx in stable_idx]}\n",
    "\n",
    "with open(\"datasets/CIFAR10/cifar10_relu_patterns_{}.json\", \"w\") as f:\n",
    "    json.dump(stable_relu_patterns, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[775  16  33  21  18   4   6  10  67  50]\n",
      " [ 12 833   3  10   3   2  11   2  24 100]\n",
      " [ 57   4 560  85 122  75  51  26   6  14]\n",
      " [ 10   5  47 563  66 212  42  22  14  19]\n",
      " [ 19   3  34  67 734  33  29  64  12   5]\n",
      " [ 14   2  29 154  55 687  12  37   5   5]\n",
      " [  7   5  24  77  50  28 796   3   4   6]\n",
      " [ 10   1  19  45  60  74   5 773   2  11]\n",
      " [ 34  31   7  18   4   3   3   5 863  32]\n",
      " [ 24  64   6  20   7   6   3  12  26 832]]\n",
      "0.7416\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check accuracy of the loaded model. Expected: 74.16%\n",
    "\"\"\"\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "for idx in range(len(test_images)):\n",
    "    input = (test_images[idx]/255).astype(np.float32).reshape(1,32,32,3)\n",
    "    # print(input, input.shape)\n",
    "    pred = pytorch_model(torch.Tensor(input))\n",
    "    # print(pred, np.argmax(pred), labels[idx])\n",
    "    true_labels.append(test_labels[idx])\n",
    "    if pred is not None:\n",
    "        pred_labels.append(torch.argmax(pred))\n",
    "    else:\n",
    "        pred_labels.append(-1)\n",
    "print(confusion_matrix(true_labels, pred_labels))\n",
    "print(accuracy_score(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "input = (test_images[idx]/255).astype(np.float32).reshape(1,32,32,3)\n",
    "print(marabou_network.evaluate(input))\n",
    "print(pytorch_model(torch.Tensor(input)))\n",
    "marabou_network.reluList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('abc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4f30c81410d6dc92032e13442d5bad0b7257e5d0e3f93d21255b7753ef9c37b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
